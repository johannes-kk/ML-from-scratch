{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Bootstrap Aggregation (Bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, randrange\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "* Bootstrap aggregating decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random subsample from the dataset with replacement\n",
    "# Input: dataset to bootstrap, ratio of dataset to use for bootstrap sample (e.g. 70% = 0.7)\n",
    "# Output: bootstrapped dataset sample\n",
    "def bootstrap_subsample(dataset, ratio = 1.0):\n",
    "    # Create empty list for new bootstrapped sample\n",
    "    sample = list()\n",
    "    # Get number of observations in bootstrapped sample\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    # Randomly add observations from dataset to bootstrap sample, with replacement\n",
    "    while len(sample) < n_sample:\n",
    "        index = randrange(len(dataset))\n",
    "        sample.append(dataset[index])\n",
    "    return sample\n",
    "\n",
    "# For a set of bagged trees, makes a prediction with each and combines into a single return prediction\n",
    "# Input: row to predict output, list of bagged trees with whom to get prediction\n",
    "# Output: predicted class; most common prediction among the bagged trees\n",
    "def bagging_predict_mode(trees, row):\n",
    "    # For given row, get prediction of each bagged tree in 'trees' and add to list of tree predictions\n",
    "    predictions = [cart_predict(tree, row) for tree in trees]\n",
    "    # Select most common prediction from those made by the bagged trees, and return as prediction\n",
    "    return max(set(predictions), key=predictions.count)\n",
    "\n",
    "# Creates bootstrapped samples, trains a decision tree on each, then predicts using the bagged trees\n",
    "# Input: train and test sets, max tree depth, min rows per branch, sample size ratio, num trees/samples\n",
    "# Output: list of predictions for provided test rows, using provided train rows to bootstrap aggregate\n",
    "def cart_bagging(train, test, max_depth, min_size, sample_size, n_trees):\n",
    "    trees = list()\n",
    "    # Iterate over number of trees, i.e. number of bootstrapped subsamples\n",
    "    for i in range(n_trees):\n",
    "        # Create a bootstrapped subsample for the current tree\n",
    "        sample = bootstrap_subsample(train, sample_size)\n",
    "        # Build a tree, fitted on the \"constructed\" bootstrapped subsample\n",
    "        tree = cart_build_tree(sample, max_depth, min_size)\n",
    "        # Add tree to list of n_trees trees\n",
    "        trees.append(tree)\n",
    "    # Get prediction of bagged trees for all rows in test dataset\n",
    "    predictions = [bagging_predict_mode(trees, row) for row in test]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing bagging on contrived dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: [[2], [9], [1], [4], [1], [7], [7], [7], [6], [3], [1], [7], [0], [6], [6], [9], [0], [7], [4], [3]]\n",
      "True Mean: 4.500\n",
      "Samples=1, Estimated Mean: 4.000\n",
      "Samples=10, Estimated Mean: 4.700\n",
      "Samples=100, Estimated Mean: 4.570\n"
     ]
    }
   ],
   "source": [
    "# Contrived dataset for testing\n",
    "seed(1)\n",
    "# Create list of 20 random numbers between 0 and 9 (inclusive) => contrived dataset\n",
    "# List of lists since each observation is typically a list of numbers (columns)\n",
    "    # Though each row in this contrived dataset is one element, most functions expect row === list\n",
    "dataset = [[randrange(10)] for i in range(20)]\n",
    "print(\"Dataset:\", dataset)\n",
    "print('True Mean: %.3f' % mean([row[0] for row in dataset]))\n",
    "\n",
    "# Estimated means\n",
    "ratio = 0.10\n",
    "# Experiment with estimated means over 1, 10, and 100 samples\n",
    "for size in [1, 10, 100]:\n",
    "    sample_means = list()\n",
    "    # For each sample, create a bootstrapped subsample and calculate the mean value\n",
    "    for i in range(size):\n",
    "        sample = bootstrap_subsample(dataset, ratio)\n",
    "        sample_mean = mean([row[0] for row in sample])\n",
    "        sample_means.append(sample_mean)\n",
    "    # After the samples are created, calculate their average estimate of the mean\n",
    "    print('Samples=%d, Estimated Mean: %.3f' % (size, mean(sample_means)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing bagging on Sonar dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sonar Case Study:\n",
      "Loaded data file data/sonar.all-data.csv with 208 rows and 61 columns.\n",
      "\n",
      "Trees: 1\n",
      "Scores: [60.97560975609756, 65.85365853658537, 58.536585365853654, 63.41463414634146, 65.85365853658537]\n",
      "Mean Accuracy: 62.927%\n",
      "\n",
      "Trees: 5\n",
      "Scores: [65.85365853658537, 56.09756097560976, 68.29268292682927, 68.29268292682927, 53.65853658536586]\n",
      "Mean Accuracy: 62.439%\n",
      "\n",
      "Trees: 10\n",
      "Scores: [56.09756097560976, 63.41463414634146, 68.29268292682927, 75.60975609756098, 60.97560975609756]\n",
      "Mean Accuracy: 64.878%\n",
      "\n",
      "Trees: 50\n",
      "Scores: [73.17073170731707, 70.73170731707317, 68.29268292682927, 65.85365853658537, 73.17073170731707]\n",
      "Mean Accuracy: 70.244%\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "\n",
    "# Load and prepare data\n",
    "print(\"\\nSonar Case Study:\")\n",
    "dataset = load_csv('data/sonar.all-data.csv')\n",
    "# Convert string attributes to floats\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "# Convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "\n",
    "# Evaluate algorithm\n",
    "# 208/5 ~ 41 records evaluated upon each iteration => 41 test, 167 train => 5 times\n",
    "n_folds = 5\n",
    "\n",
    "# Relatively deep trees are permitted, with relatively narrow branches (few records) allowed\n",
    "max_depth = 6\n",
    "min_size = 2\n",
    "# Each bootstrap sample is half the size of the dataset (with replacement)\n",
    "    # This is to force some variety in the dataset subsamples used to train each tree\n",
    "    # The default for bagging is to have size of sample datasets match original training dataset\n",
    "sample_size = 0.50\n",
    "\n",
    "# Run the algorithm for different numbers of samples (hence bagged trees, since one per sample)\n",
    "    # Primarily to demonstrate the behaviour of the algorithm\n",
    "for n_trees in [1, 5, 10, 50]:\n",
    "    scores = evaluate_algorithm(dataset, cart_bagging, n_folds, accuracy_metric, max_depth, min_size, sample_size, n_trees)\n",
    "\n",
    "    print('\\nTrees: %d' % n_trees)\n",
    "    print('Scores: %s' % scores)\n",
    "    print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
