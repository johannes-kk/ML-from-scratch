{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Learning Vector Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, randrange\n",
    "from math import sqrt\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the best matching unit\n",
    "# Input: test_row to find BMU for, and codebooks (patterns) among which to look\n",
    "# Output: the BMU; the codebook (pattern) with shortest Euclidian distance from test_row\n",
    "def get_best_matching_unit(codebooks, test_row):\n",
    "    # List of tuples; each contains a vector and its distance to test_row\n",
    "    distances = list()\n",
    "    # Iterate over codebooks (patterns to match against) to find closest match\n",
    "    for codebook in codebooks:\n",
    "        # Find Euclidian distance between test_row and current codebook (pattern)\n",
    "        dist = euclidian_distance(codebook, test_row)\n",
    "        # Add tuple of codebook (pattern) and its distance to test_row to list of tuples\n",
    "        distances.append((codebook, dist))\n",
    "    # Sort list of tuples by distance (second tuple element: tup[1]), by default in ascending order\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    # Return codebook (pattern) with shortest Euclidian distance from test_row\n",
    "    return distances[0][0]\n",
    "\n",
    "# Create a randomized codebook vector\n",
    "# Input: the training set from which to pull random feature values\n",
    "# Output: a codebook vector with randomized feature pattern values from among the training set\n",
    "def random_codebook(train):\n",
    "    n_records = len(train)\n",
    "    # Number of features /  input variables / columns\n",
    "    n_features = len(train[0])\n",
    "    # Initialize codebook as a vector (set) of random features from training data\n",
    "    # For each feature, take that of a random record in the training set\n",
    "    codebook = [train[randrange(n_records)][i] for i in range(n_features)]\n",
    "    return codebook\n",
    "\n",
    "# Make a prediction with codebook vectors\n",
    "# Input: codebook vectors (\"blueprint\" class patterns), test row to predict for\n",
    "# Output: predicted class for test row\n",
    "def predict_LVQ(codebooks, test_row):\n",
    "    # Find best matching unit, i.e. codebook vector whose pattern has least Euclidian distance\n",
    "    bmu = get_best_matching_unit(codebooks, test_row)\n",
    "    # Return the BMU class as the prediction\n",
    "    return bmu[-1]\n",
    "\n",
    "# Train a number of codebook vector feature values for a provided dataset, with learning rate decay\n",
    "# Input: training data, number of codebooks (patterns), initial learning rate, number of epochs\n",
    "# Output: list of tuned codebook vectors (practically class blueprint patterns of input data)\n",
    "def train_codebooks(train, n_codebooks, lrate, epochs):\n",
    "    # Populate a list[] of randomly initialized codebook vectors (\"class\" input data patterns)\n",
    "    codebooks = [random_codebook(train) for i in range(n_codebooks)]\n",
    "    for epoch in range(epochs):\n",
    "        # Update effective learning rate through epoch-based decay\n",
    "        rate = lrate * (1.0 - (epoch / float(epochs)))\n",
    "        # Start epoch error rate at 0\n",
    "        sum_error = 0.0\n",
    "        # Per epoch, iterate over all rows in train\n",
    "        for row in train:\n",
    "            # Find BMU of row from among codebook vectors\n",
    "            bmu = get_best_matching_unit(codebooks, row)\n",
    "            # Iterate over features to update codebook vector (i.e. \"blueprint\" class pattern)\n",
    "            for i in range(len(row)-1):\n",
    "                # Calculate feature value difference between BMU and current training row\n",
    "                error = row[i] - bmu[i]\n",
    "                # Add to epoch sum squared error\n",
    "                sum_error += error**2\n",
    "                # If last column of BMU same as train row, hence same (correct) class\n",
    "                if bmu[-1] == row[-1]:\n",
    "                    # Increment BMU feature value to bring it closer to train row feature value\n",
    "                    # E.g. row[i] > bmu[i], then adding rate*error increases bmu[i] closer to row[i]\n",
    "                    bmu[i] += rate * error\n",
    "                # BMU is a different class, hence wrong prediction\n",
    "                else:\n",
    "                    # Decrement BMU feature value, i.e. moving it further from the test row pattern\n",
    "                    bmu[i] -= rate * error\n",
    "        print(\">epoch%d, lrate=%.3f, error=%.3f\" % (epoch, rate, sum_error))\n",
    "    return codebooks\n",
    "\n",
    "# Learning Vector Quantization Algorithm\n",
    "def learning_vector_quantization(train, test, n_codebooks, lrate, epochs):\n",
    "    # Train codebook vector feature values\n",
    "    codebooks = train_codebooks(train, n_codebooks, lrate, epochs)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        # Get predicted class based for given row based on trained codebook vectors\n",
    "        output = predict_LVQ(codebooks, row)\n",
    "        predictions.append(output)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing LVQ on contrived dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.33\n",
      "1.95\n",
      "1.56\n",
      "0.54\n",
      "4.85\n",
      "2.59\n",
      "4.21\n",
      "6.52\n",
      "4.99\n",
      "\n",
      " First row: [2.7810836, 2.550537003, 0]\n",
      " BMU:       [2.7810836, 2.550537003, 0]\n",
      "\n",
      "Testing training function:\n",
      ">epoch0, lrate=0.300, error=43.270\n",
      ">epoch1, lrate=0.270, error=30.403\n",
      ">epoch2, lrate=0.240, error=27.146\n",
      ">epoch3, lrate=0.210, error=26.301\n",
      ">epoch4, lrate=0.180, error=25.537\n",
      ">epoch5, lrate=0.150, error=24.789\n",
      ">epoch6, lrate=0.120, error=24.058\n",
      ">epoch7, lrate=0.090, error=23.346\n",
      ">epoch8, lrate=0.060, error=22.654\n",
      ">epoch9, lrate=0.030, error=21.982\n",
      "Codebooks: [[2.432316086217663, 2.839821664184211, 0], [7.319592257892681, 1.97013382654341, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Contrived dataset for testing\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "    [1.465489372,2.362125076,0],\n",
    "    [3.396561688,4.400293529,0],\n",
    "    [1.38807019,1.850220317,0],\n",
    "    [3.06407232,3.005305973,0],\n",
    "    [7.627531214,2.759262235,1],\n",
    "    [5.332441248,2.088626775,1],\n",
    "    [6.922596716,1.77106367,1],\n",
    "    [8.675418651,-0.242068655,1],\n",
    "    [7.673756466,3.508563011,1]]\n",
    "\n",
    "# Testing Euclidian distance\n",
    "row0 = dataset[0]\n",
    "for row in dataset:\n",
    "    distance = euclidian_distance(row0, row)\n",
    "    print(round(distance, 2))\n",
    "\n",
    "# Testing Best Matching Unit (BMU) function\n",
    "test_row = dataset[0]\n",
    "bmu = get_best_matching_unit(dataset, test_row)\n",
    "print(\"\\n First row:\", dataset[0])\n",
    "print(\" BMU:      \", bmu)\n",
    "# As expected, the most similar codebook to the first row is the first row (itself)\n",
    "# Making predictions with a set of codebook vectors is the same thing.\n",
    "# We use 1-nearest neighbour algorithm, but look among codebooks rather than full training set\n",
    "\n",
    "# Testing codebook training function\n",
    "seed(1)\n",
    "learn_rate = 0.3\n",
    "n_epochs = 10\n",
    "n_codebooks = 2\n",
    "print(\"\\nTesting training function:\")\n",
    "codebooks = train_codebooks(dataset, n_codebooks, learn_rate, n_epochs)\n",
    "print(\"Codebooks: %s\" % codebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing LVQ on Ionosphere dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data file data/ionosphere.csv with 351 rows and 35 columns.\n",
      "\n",
      "Ionsophere Case Study:\n",
      ">epoch0, lrate=0.300, error=2106.606\n",
      ">epoch1, lrate=0.294, error=2033.558\n",
      ">epoch2, lrate=0.288, error=1931.089\n",
      ">epoch3, lrate=0.282, error=1899.031\n",
      ">epoch4, lrate=0.276, error=1906.729\n",
      ">epoch5, lrate=0.270, error=1881.332\n",
      ">epoch6, lrate=0.264, error=1869.365\n",
      ">epoch7, lrate=0.258, error=1857.928\n",
      ">epoch8, lrate=0.252, error=1839.964\n",
      ">epoch9, lrate=0.246, error=1839.005\n",
      ">epoch10, lrate=0.240, error=1824.272\n",
      ">epoch11, lrate=0.234, error=1825.209\n",
      ">epoch12, lrate=0.228, error=1807.112\n",
      ">epoch13, lrate=0.222, error=1798.466\n",
      ">epoch14, lrate=0.216, error=1788.285\n",
      ">epoch15, lrate=0.210, error=1776.740\n",
      ">epoch16, lrate=0.204, error=1763.173\n",
      ">epoch17, lrate=0.198, error=1755.526\n",
      ">epoch18, lrate=0.192, error=1747.907\n",
      ">epoch19, lrate=0.186, error=1740.369\n",
      ">epoch20, lrate=0.180, error=1729.157\n",
      ">epoch21, lrate=0.174, error=1721.589\n",
      ">epoch22, lrate=0.168, error=1714.244\n",
      ">epoch23, lrate=0.162, error=1706.964\n",
      ">epoch24, lrate=0.156, error=1699.747\n",
      ">epoch25, lrate=0.150, error=1692.593\n",
      ">epoch26, lrate=0.144, error=1685.500\n",
      ">epoch27, lrate=0.138, error=1675.505\n",
      ">epoch28, lrate=0.132, error=1667.345\n",
      ">epoch29, lrate=0.126, error=1660.423\n",
      ">epoch30, lrate=0.120, error=1653.611\n",
      ">epoch31, lrate=0.114, error=1646.856\n",
      ">epoch32, lrate=0.108, error=1640.152\n",
      ">epoch33, lrate=0.102, error=1633.494\n",
      ">epoch34, lrate=0.096, error=1625.923\n",
      ">epoch35, lrate=0.090, error=1616.337\n",
      ">epoch36, lrate=0.084, error=1612.402\n",
      ">epoch37, lrate=0.078, error=1602.819\n",
      ">epoch38, lrate=0.072, error=1594.030\n",
      ">epoch39, lrate=0.066, error=1583.865\n",
      ">epoch40, lrate=0.060, error=1576.944\n",
      ">epoch41, lrate=0.054, error=1569.737\n",
      ">epoch42, lrate=0.048, error=1562.576\n",
      ">epoch43, lrate=0.042, error=1555.506\n",
      ">epoch44, lrate=0.036, error=1546.954\n",
      ">epoch45, lrate=0.030, error=1539.397\n",
      ">epoch46, lrate=0.024, error=1532.416\n",
      ">epoch47, lrate=0.018, error=1525.976\n",
      ">epoch48, lrate=0.012, error=1520.160\n",
      ">epoch49, lrate=0.006, error=1514.873\n",
      ">epoch0, lrate=0.300, error=2181.780\n",
      ">epoch1, lrate=0.294, error=2008.299\n",
      ">epoch2, lrate=0.288, error=1816.997\n",
      ">epoch3, lrate=0.282, error=1823.952\n",
      ">epoch4, lrate=0.276, error=1738.812\n",
      ">epoch5, lrate=0.270, error=1739.807\n",
      ">epoch6, lrate=0.264, error=1717.884\n",
      ">epoch7, lrate=0.258, error=1704.385\n",
      ">epoch8, lrate=0.252, error=1673.767\n",
      ">epoch9, lrate=0.246, error=1672.122\n",
      ">epoch10, lrate=0.240, error=1707.404\n",
      ">epoch11, lrate=0.234, error=1674.701\n",
      ">epoch12, lrate=0.228, error=1661.894\n",
      ">epoch13, lrate=0.222, error=1636.671\n",
      ">epoch14, lrate=0.216, error=1628.820\n",
      ">epoch15, lrate=0.210, error=1622.320\n",
      ">epoch16, lrate=0.204, error=1616.075\n",
      ">epoch17, lrate=0.198, error=1609.956\n",
      ">epoch18, lrate=0.192, error=1603.940\n",
      ">epoch19, lrate=0.186, error=1598.019\n",
      ">epoch20, lrate=0.180, error=1592.193\n",
      ">epoch21, lrate=0.174, error=1591.137\n",
      ">epoch22, lrate=0.168, error=1582.012\n",
      ">epoch23, lrate=0.162, error=1576.302\n",
      ">epoch24, lrate=0.156, error=1570.664\n",
      ">epoch25, lrate=0.150, error=1565.093\n",
      ">epoch26, lrate=0.144, error=1559.585\n",
      ">epoch27, lrate=0.138, error=1546.670\n",
      ">epoch28, lrate=0.132, error=1547.587\n",
      ">epoch29, lrate=0.126, error=1535.526\n",
      ">epoch30, lrate=0.120, error=1528.884\n",
      ">epoch31, lrate=0.114, error=1523.503\n",
      ">epoch32, lrate=0.108, error=1518.138\n",
      ">epoch33, lrate=0.102, error=1512.791\n",
      ">epoch34, lrate=0.096, error=1507.454\n",
      ">epoch35, lrate=0.090, error=1502.118\n",
      ">epoch36, lrate=0.084, error=1496.028\n",
      ">epoch37, lrate=0.078, error=1491.477\n",
      ">epoch38, lrate=0.072, error=1481.813\n",
      ">epoch39, lrate=0.066, error=1476.406\n",
      ">epoch40, lrate=0.060, error=1470.257\n",
      ">epoch41, lrate=0.054, error=1465.122\n",
      ">epoch42, lrate=0.048, error=1459.093\n",
      ">epoch43, lrate=0.042, error=1449.233\n",
      ">epoch44, lrate=0.036, error=1443.913\n",
      ">epoch45, lrate=0.030, error=1437.709\n",
      ">epoch46, lrate=0.024, error=1431.552\n",
      ">epoch47, lrate=0.018, error=1425.121\n",
      ">epoch48, lrate=0.012, error=1420.045\n",
      ">epoch49, lrate=0.006, error=1415.726\n",
      ">epoch0, lrate=0.300, error=2147.531\n",
      ">epoch1, lrate=0.294, error=1986.910\n",
      ">epoch2, lrate=0.288, error=1854.645\n",
      ">epoch3, lrate=0.282, error=1892.776\n",
      ">epoch4, lrate=0.276, error=1957.991\n",
      ">epoch5, lrate=0.270, error=1857.629\n",
      ">epoch6, lrate=0.264, error=1796.273\n",
      ">epoch7, lrate=0.258, error=1832.365\n",
      ">epoch8, lrate=0.252, error=1799.814\n",
      ">epoch9, lrate=0.246, error=1796.466\n",
      ">epoch10, lrate=0.240, error=1780.154\n",
      ">epoch11, lrate=0.234, error=1760.888\n",
      ">epoch12, lrate=0.228, error=1756.720\n",
      ">epoch13, lrate=0.222, error=1749.692\n",
      ">epoch14, lrate=0.216, error=1752.038\n",
      ">epoch15, lrate=0.210, error=1744.134\n",
      ">epoch16, lrate=0.204, error=1728.916\n",
      ">epoch17, lrate=0.198, error=1731.577\n",
      ">epoch18, lrate=0.192, error=1716.023\n",
      ">epoch19, lrate=0.186, error=1712.586\n",
      ">epoch20, lrate=0.180, error=1696.747\n",
      ">epoch21, lrate=0.174, error=1691.262\n",
      ">epoch22, lrate=0.168, error=1686.195\n",
      ">epoch23, lrate=0.162, error=1681.226\n",
      ">epoch24, lrate=0.156, error=1670.884\n",
      ">epoch25, lrate=0.150, error=1660.434\n",
      ">epoch26, lrate=0.144, error=1653.224\n",
      ">epoch27, lrate=0.138, error=1646.720\n",
      ">epoch28, lrate=0.132, error=1640.266\n",
      ">epoch29, lrate=0.126, error=1633.864\n",
      ">epoch30, lrate=0.120, error=1627.511\n",
      ">epoch31, lrate=0.114, error=1621.201\n",
      ">epoch32, lrate=0.108, error=1612.806\n",
      ">epoch33, lrate=0.102, error=1606.722\n",
      ">epoch34, lrate=0.096, error=1601.947\n",
      ">epoch35, lrate=0.090, error=1594.169\n",
      ">epoch36, lrate=0.084, error=1587.167\n",
      ">epoch37, lrate=0.078, error=1580.105\n",
      ">epoch38, lrate=0.072, error=1573.381\n",
      ">epoch39, lrate=0.066, error=1563.877\n",
      ">epoch40, lrate=0.060, error=1556.810\n",
      ">epoch41, lrate=0.054, error=1550.194\n",
      ">epoch42, lrate=0.048, error=1543.683\n",
      ">epoch43, lrate=0.042, error=1537.272\n",
      ">epoch44, lrate=0.036, error=1529.410\n",
      ">epoch45, lrate=0.030, error=1522.852\n",
      ">epoch46, lrate=0.024, error=1516.956\n",
      ">epoch47, lrate=0.018, error=1511.481\n",
      ">epoch48, lrate=0.012, error=1506.498\n",
      ">epoch49, lrate=0.006, error=1502.265\n",
      ">epoch0, lrate=0.300, error=2181.818\n",
      ">epoch1, lrate=0.294, error=1917.477\n",
      ">epoch2, lrate=0.288, error=1889.924\n",
      ">epoch3, lrate=0.282, error=1817.013\n",
      ">epoch4, lrate=0.276, error=1808.763\n",
      ">epoch5, lrate=0.270, error=1791.149\n",
      ">epoch6, lrate=0.264, error=1776.677\n",
      ">epoch7, lrate=0.258, error=1759.034\n",
      ">epoch8, lrate=0.252, error=1763.785\n",
      ">epoch9, lrate=0.246, error=1733.374\n",
      ">epoch10, lrate=0.240, error=1727.603\n",
      ">epoch11, lrate=0.234, error=1724.615\n",
      ">epoch12, lrate=0.228, error=1712.586\n",
      ">epoch13, lrate=0.222, error=1705.660\n",
      ">epoch14, lrate=0.216, error=1697.761\n",
      ">epoch15, lrate=0.210, error=1692.048\n",
      ">epoch16, lrate=0.204, error=1684.955\n",
      ">epoch17, lrate=0.198, error=1677.927\n",
      ">epoch18, lrate=0.192, error=1670.974\n",
      ">epoch19, lrate=0.186, error=1671.180\n",
      ">epoch20, lrate=0.180, error=1649.235\n",
      ">epoch21, lrate=0.174, error=1639.416\n",
      ">epoch22, lrate=0.168, error=1632.867\n",
      ">epoch23, lrate=0.162, error=1626.682\n",
      ">epoch24, lrate=0.156, error=1620.518\n",
      ">epoch25, lrate=0.150, error=1614.411\n",
      ">epoch26, lrate=0.144, error=1608.377\n",
      ">epoch27, lrate=0.138, error=1602.398\n",
      ">epoch28, lrate=0.132, error=1590.640\n",
      ">epoch29, lrate=0.126, error=1586.138\n",
      ">epoch30, lrate=0.120, error=1575.365\n",
      ">epoch31, lrate=0.114, error=1571.139\n",
      ">epoch32, lrate=0.108, error=1562.711\n",
      ">epoch33, lrate=0.102, error=1560.236\n",
      ">epoch34, lrate=0.096, error=1552.431\n",
      ">epoch35, lrate=0.090, error=1547.713\n",
      ">epoch36, lrate=0.084, error=1538.824\n",
      ">epoch37, lrate=0.078, error=1537.941\n",
      ">epoch38, lrate=0.072, error=1530.803\n",
      ">epoch39, lrate=0.066, error=1524.776\n",
      ">epoch40, lrate=0.060, error=1515.632\n",
      ">epoch41, lrate=0.054, error=1510.647\n",
      ">epoch42, lrate=0.048, error=1503.176\n",
      ">epoch43, lrate=0.042, error=1499.169\n",
      ">epoch44, lrate=0.036, error=1492.206\n",
      ">epoch45, lrate=0.030, error=1486.903\n",
      ">epoch46, lrate=0.024, error=1481.280\n",
      ">epoch47, lrate=0.018, error=1476.650\n",
      ">epoch48, lrate=0.012, error=1471.812\n",
      ">epoch49, lrate=0.006, error=1467.946\n",
      ">epoch0, lrate=0.300, error=1887.232\n",
      ">epoch1, lrate=0.294, error=1769.266\n",
      ">epoch2, lrate=0.288, error=1653.149\n",
      ">epoch3, lrate=0.282, error=1626.090\n",
      ">epoch4, lrate=0.276, error=1612.971\n",
      ">epoch5, lrate=0.270, error=1611.821\n",
      ">epoch6, lrate=0.264, error=1604.982\n",
      ">epoch7, lrate=0.258, error=1598.846\n",
      ">epoch8, lrate=0.252, error=1592.942\n",
      ">epoch9, lrate=0.246, error=1587.179\n",
      ">epoch10, lrate=0.240, error=1570.185\n",
      ">epoch11, lrate=0.234, error=1531.840\n",
      ">epoch12, lrate=0.228, error=1519.024\n",
      ">epoch13, lrate=0.222, error=1513.307\n",
      ">epoch14, lrate=0.216, error=1509.179\n",
      ">epoch15, lrate=0.210, error=1503.451\n",
      ">epoch16, lrate=0.204, error=1494.493\n",
      ">epoch17, lrate=0.198, error=1488.614\n",
      ">epoch18, lrate=0.192, error=1482.874\n",
      ">epoch19, lrate=0.186, error=1477.178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch20, lrate=0.180, error=1471.520\n",
      ">epoch21, lrate=0.174, error=1465.897\n",
      ">epoch22, lrate=0.168, error=1460.311\n",
      ">epoch23, lrate=0.162, error=1458.982\n",
      ">epoch24, lrate=0.156, error=1449.192\n",
      ">epoch25, lrate=0.150, error=1439.539\n",
      ">epoch26, lrate=0.144, error=1431.698\n",
      ">epoch27, lrate=0.138, error=1423.412\n",
      ">epoch28, lrate=0.132, error=1417.905\n",
      ">epoch29, lrate=0.126, error=1417.880\n",
      ">epoch30, lrate=0.120, error=1406.439\n",
      ">epoch31, lrate=0.114, error=1405.912\n",
      ">epoch32, lrate=0.108, error=1393.973\n",
      ">epoch33, lrate=0.102, error=1391.508\n",
      ">epoch34, lrate=0.096, error=1382.632\n",
      ">epoch35, lrate=0.090, error=1381.079\n",
      ">epoch36, lrate=0.084, error=1373.857\n",
      ">epoch37, lrate=0.078, error=1370.051\n",
      ">epoch38, lrate=0.072, error=1362.348\n",
      ">epoch39, lrate=0.066, error=1357.132\n",
      ">epoch40, lrate=0.060, error=1351.590\n",
      ">epoch41, lrate=0.054, error=1346.953\n",
      ">epoch42, lrate=0.048, error=1341.475\n",
      ">epoch43, lrate=0.042, error=1335.893\n",
      ">epoch44, lrate=0.036, error=1331.728\n",
      ">epoch45, lrate=0.030, error=1325.676\n",
      ">epoch46, lrate=0.024, error=1321.145\n",
      ">epoch47, lrate=0.018, error=1315.750\n",
      ">epoch48, lrate=0.012, error=1311.166\n",
      ">epoch49, lrate=0.006, error=1306.407\n",
      "Scores: [88.57142857142857, 90.0, 88.57142857142857, 88.57142857142857, 80.0]\n",
      "Mean Accuracy: 87.143%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Ionosphere Case Study\n",
    "seed(1)\n",
    "dataset = load_csv(\"data/ionosphere.csv\")\n",
    "# Convert string numbers to floats\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "# Convert class column from string to integer\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "\n",
    "# Evaluate algorithm\n",
    "print(\"\\nIonsophere Case Study:\")\n",
    "n_folds = 5\n",
    "learn_rate = 0.3\n",
    "n_epochs = 50\n",
    "n_codebooks = 20\n",
    "# n_codebooks, learn_rate, and n_epochs are passed via *args\n",
    "scores = evaluate_algorithm(dataset, learning_vector_quantization, n_folds, accuracy_metric, n_codebooks, learn_rate, n_epochs)\n",
    "print(\"Scores: %s\" % scores)\n",
    "print(\"Mean Accuracy: %.3f%%\" % (sum(scores)/float(len(scores))))\n",
    "# 87.143% is better than the baseline of 64.286%\n",
    "# 20 codebooks is also far less than holding the entire dataset, like we would have to with KNN\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
