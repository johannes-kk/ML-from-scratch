{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, randrange\n",
    "from math import exp\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions\n",
    "* Logistic regression using stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a logistic prediction, provided row and coefficients\n",
    "def predict_logistic(row, coefficients):\n",
    "    yhat = coefficients[0]\n",
    "    for i in range(len(row)-1):\n",
    "        yhat += coefficients[i + 1] * row[i]\n",
    "    return 1.0 / (1.0 + exp(-yhat))\n",
    "\n",
    "# Estimate logistic regression coefficients using stochastic gradient descent (SGD)\n",
    "# Returns list of coefficients, with intercept at first index\n",
    "# Batch size b = 1 means stochastic gradient descent, b > 1 means (mini) batch gradient descent\n",
    "def coefficients_logistic_sgd(train, l_rate, n_epoch, b = 1):\n",
    "    #coef = [0.0 for row in train]\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        # Sum squared errors to track epoch performance\n",
    "        sum_error = 0\n",
    "        # Counter to track mini batch\n",
    "        i = 0\n",
    "        # Counter to track overall row, to capture mid-batch end of dataset\n",
    "        j = 0\n",
    "        # SUM(h - y) * Xi over coefficients i, to multiply full batch by learning rate\n",
    "        adjustments = [0 for col in range(len(train[0]))]\n",
    "        for row in train:\n",
    "            i += 1\n",
    "            j += 1\n",
    "            yhat = predict_logistic(row, coef)\n",
    "            error = row[-1] - yhat\n",
    "            # Add to overall epoch error\n",
    "            sum_error += error**2\n",
    "            # Add intercept error, since has no corresponding input Xi\n",
    "            adjustments[0] += error\n",
    "            for k in range(len(row)-1):\n",
    "                # Begin with first coefficient, skipping intercept at k = 0\n",
    "                adjustments[k + 1] += error * row[k]\n",
    "\n",
    "            # Check whether this row is last in batch, or in overall dataset\n",
    "            if i == b or j == len(train):\n",
    "                # Iterate over all coefficients, including intercept\n",
    "                for k in range(len(adjustments)):\n",
    "                    coef[k] = coef[k] + l_rate * (1/i) * adjustments[k] * yhat * (1.0 - yhat)\n",
    "\n",
    "                adjustments = [0 for col in range(len(train[0]))]\n",
    "                i = 0\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch+1, l_rate, sum_error))\n",
    "    return coef\n",
    "\n",
    "# Logistic Regression Algorithm with Stochastic Gradient Descent\n",
    "# Parameters: learning rate, number of epochs, (mini-) batch size\n",
    "def logistic_regression_sgd(train, test, l_rate, n_epoch, b_size = 1):\n",
    "    # Empty list to hold predictions matching test actual y's\n",
    "    predictions = list()\n",
    "    # Estimate coefficients using provided parameters and SGD\n",
    "    coef = coefficients_logistic_sgd(train, l_rate, n_epoch, b_size)\n",
    "    for row in test:\n",
    "        # Predict yhat using estimated coefficients\n",
    "        yhat = predict_logistic(row, coef)\n",
    "        # Round to 0 or 1\n",
    "        yhat = round(yhat)\n",
    "        # Add integer yhat to list of predictions\n",
    "        predictions.append(yhat)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0.000, Predicted=0.299 [0]\n",
      "Expected=0.000, Predicted=0.146 [0]\n",
      "Expected=0.000, Predicted=0.085 [0]\n",
      "Expected=0.000, Predicted=0.220 [0]\n",
      "Expected=0.000, Predicted=0.247 [0]\n",
      "Expected=1.000, Predicted=0.955 [1]\n",
      "Expected=1.000, Predicted=0.862 [1]\n",
      "Expected=1.000, Predicted=0.972 [1]\n",
      "Expected=1.000, Predicted=0.999 [1]\n",
      "Expected=1.000, Predicted=0.905 [1]\n",
      "\n",
      ">epoch=1, lrate=0.300, error=2.217\n",
      ">epoch=2, lrate=0.300, error=1.613\n",
      ">epoch=3, lrate=0.300, error=1.113\n",
      ">epoch=4, lrate=0.300, error=0.827\n",
      ">epoch=5, lrate=0.300, error=0.623\n",
      ">epoch=6, lrate=0.300, error=0.494\n",
      ">epoch=7, lrate=0.300, error=0.412\n",
      ">epoch=8, lrate=0.300, error=0.354\n",
      ">epoch=9, lrate=0.300, error=0.310\n",
      ">epoch=10, lrate=0.300, error=0.276\n",
      ">epoch=11, lrate=0.300, error=0.248\n",
      ">epoch=12, lrate=0.300, error=0.224\n",
      ">epoch=13, lrate=0.300, error=0.205\n",
      ">epoch=14, lrate=0.300, error=0.189\n",
      ">epoch=15, lrate=0.300, error=0.174\n",
      ">epoch=16, lrate=0.300, error=0.162\n",
      ">epoch=17, lrate=0.300, error=0.151\n",
      ">epoch=18, lrate=0.300, error=0.142\n",
      ">epoch=19, lrate=0.300, error=0.134\n",
      ">epoch=20, lrate=0.300, error=0.126\n",
      ">epoch=21, lrate=0.300, error=0.119\n",
      ">epoch=22, lrate=0.300, error=0.113\n",
      ">epoch=23, lrate=0.300, error=0.108\n",
      ">epoch=24, lrate=0.300, error=0.103\n",
      ">epoch=25, lrate=0.300, error=0.098\n",
      ">epoch=26, lrate=0.300, error=0.094\n",
      ">epoch=27, lrate=0.300, error=0.090\n",
      ">epoch=28, lrate=0.300, error=0.087\n",
      ">epoch=29, lrate=0.300, error=0.084\n",
      ">epoch=30, lrate=0.300, error=0.080\n",
      ">epoch=31, lrate=0.300, error=0.078\n",
      ">epoch=32, lrate=0.300, error=0.075\n",
      ">epoch=33, lrate=0.300, error=0.073\n",
      ">epoch=34, lrate=0.300, error=0.070\n",
      ">epoch=35, lrate=0.300, error=0.068\n",
      ">epoch=36, lrate=0.300, error=0.066\n",
      ">epoch=37, lrate=0.300, error=0.064\n",
      ">epoch=38, lrate=0.300, error=0.062\n",
      ">epoch=39, lrate=0.300, error=0.060\n",
      ">epoch=40, lrate=0.300, error=0.059\n",
      ">epoch=41, lrate=0.300, error=0.057\n",
      ">epoch=42, lrate=0.300, error=0.056\n",
      ">epoch=43, lrate=0.300, error=0.054\n",
      ">epoch=44, lrate=0.300, error=0.053\n",
      ">epoch=45, lrate=0.300, error=0.052\n",
      ">epoch=46, lrate=0.300, error=0.051\n",
      ">epoch=47, lrate=0.300, error=0.050\n",
      ">epoch=48, lrate=0.300, error=0.048\n",
      ">epoch=49, lrate=0.300, error=0.047\n",
      ">epoch=50, lrate=0.300, error=0.046\n",
      ">epoch=51, lrate=0.300, error=0.045\n",
      ">epoch=52, lrate=0.300, error=0.044\n",
      ">epoch=53, lrate=0.300, error=0.044\n",
      ">epoch=54, lrate=0.300, error=0.043\n",
      ">epoch=55, lrate=0.300, error=0.042\n",
      ">epoch=56, lrate=0.300, error=0.041\n",
      ">epoch=57, lrate=0.300, error=0.040\n",
      ">epoch=58, lrate=0.300, error=0.040\n",
      ">epoch=59, lrate=0.300, error=0.039\n",
      ">epoch=60, lrate=0.300, error=0.038\n",
      ">epoch=61, lrate=0.300, error=0.038\n",
      ">epoch=62, lrate=0.300, error=0.037\n",
      ">epoch=63, lrate=0.300, error=0.036\n",
      ">epoch=64, lrate=0.300, error=0.036\n",
      ">epoch=65, lrate=0.300, error=0.035\n",
      ">epoch=66, lrate=0.300, error=0.035\n",
      ">epoch=67, lrate=0.300, error=0.034\n",
      ">epoch=68, lrate=0.300, error=0.033\n",
      ">epoch=69, lrate=0.300, error=0.033\n",
      ">epoch=70, lrate=0.300, error=0.032\n",
      ">epoch=71, lrate=0.300, error=0.032\n",
      ">epoch=72, lrate=0.300, error=0.032\n",
      ">epoch=73, lrate=0.300, error=0.031\n",
      ">epoch=74, lrate=0.300, error=0.031\n",
      ">epoch=75, lrate=0.300, error=0.030\n",
      ">epoch=76, lrate=0.300, error=0.030\n",
      ">epoch=77, lrate=0.300, error=0.029\n",
      ">epoch=78, lrate=0.300, error=0.029\n",
      ">epoch=79, lrate=0.300, error=0.029\n",
      ">epoch=80, lrate=0.300, error=0.028\n",
      ">epoch=81, lrate=0.300, error=0.028\n",
      ">epoch=82, lrate=0.300, error=0.027\n",
      ">epoch=83, lrate=0.300, error=0.027\n",
      ">epoch=84, lrate=0.300, error=0.027\n",
      ">epoch=85, lrate=0.300, error=0.026\n",
      ">epoch=86, lrate=0.300, error=0.026\n",
      ">epoch=87, lrate=0.300, error=0.026\n",
      ">epoch=88, lrate=0.300, error=0.026\n",
      ">epoch=89, lrate=0.300, error=0.025\n",
      ">epoch=90, lrate=0.300, error=0.025\n",
      ">epoch=91, lrate=0.300, error=0.025\n",
      ">epoch=92, lrate=0.300, error=0.024\n",
      ">epoch=93, lrate=0.300, error=0.024\n",
      ">epoch=94, lrate=0.300, error=0.024\n",
      ">epoch=95, lrate=0.300, error=0.024\n",
      ">epoch=96, lrate=0.300, error=0.023\n",
      ">epoch=97, lrate=0.300, error=0.023\n",
      ">epoch=98, lrate=0.300, error=0.023\n",
      ">epoch=99, lrate=0.300, error=0.023\n",
      ">epoch=100, lrate=0.300, error=0.022\n",
      "[-0.8596443546618898, 1.522382511246001, -2.2187002105650167]\n",
      "\n",
      "Linear Regression With Stochastic Gradient Descent for Wine Quality:\n",
      "Loaded data file data/pima-indians-diabetes.csv with 768 rows and 9 columns.\n",
      ">epoch=1, lrate=0.100, error=146.981\n",
      ">epoch=2, lrate=0.100, error=141.468\n",
      ">epoch=3, lrate=0.100, error=139.888\n",
      ">epoch=4, lrate=0.100, error=139.042\n",
      ">epoch=5, lrate=0.100, error=138.346\n",
      ">epoch=6, lrate=0.100, error=137.687\n",
      ">epoch=7, lrate=0.100, error=137.042\n",
      ">epoch=8, lrate=0.100, error=136.408\n",
      ">epoch=9, lrate=0.100, error=135.785\n",
      ">epoch=10, lrate=0.100, error=135.175\n",
      ">epoch=11, lrate=0.100, error=134.577\n",
      ">epoch=12, lrate=0.100, error=133.993\n",
      ">epoch=13, lrate=0.100, error=133.421\n",
      ">epoch=14, lrate=0.100, error=132.862\n",
      ">epoch=15, lrate=0.100, error=132.315\n",
      ">epoch=16, lrate=0.100, error=131.780\n",
      ">epoch=17, lrate=0.100, error=131.257\n",
      ">epoch=18, lrate=0.100, error=130.745\n",
      ">epoch=19, lrate=0.100, error=130.245\n",
      ">epoch=20, lrate=0.100, error=129.756\n",
      ">epoch=21, lrate=0.100, error=129.278\n",
      ">epoch=22, lrate=0.100, error=128.810\n",
      ">epoch=23, lrate=0.100, error=128.352\n",
      ">epoch=24, lrate=0.100, error=127.904\n",
      ">epoch=25, lrate=0.100, error=127.466\n",
      ">epoch=26, lrate=0.100, error=127.038\n",
      ">epoch=27, lrate=0.100, error=126.619\n",
      ">epoch=28, lrate=0.100, error=126.208\n",
      ">epoch=29, lrate=0.100, error=125.806\n",
      ">epoch=30, lrate=0.100, error=125.413\n",
      ">epoch=31, lrate=0.100, error=125.028\n",
      ">epoch=32, lrate=0.100, error=124.652\n",
      ">epoch=33, lrate=0.100, error=124.283\n",
      ">epoch=34, lrate=0.100, error=123.922\n",
      ">epoch=35, lrate=0.100, error=123.568\n",
      ">epoch=36, lrate=0.100, error=123.221\n",
      ">epoch=37, lrate=0.100, error=122.882\n",
      ">epoch=38, lrate=0.100, error=122.549\n",
      ">epoch=39, lrate=0.100, error=122.223\n",
      ">epoch=40, lrate=0.100, error=121.904\n",
      ">epoch=41, lrate=0.100, error=121.591\n",
      ">epoch=42, lrate=0.100, error=121.284\n",
      ">epoch=43, lrate=0.100, error=120.983\n",
      ">epoch=44, lrate=0.100, error=120.688\n",
      ">epoch=45, lrate=0.100, error=120.399\n",
      ">epoch=46, lrate=0.100, error=120.115\n",
      ">epoch=47, lrate=0.100, error=119.837\n",
      ">epoch=48, lrate=0.100, error=119.564\n",
      ">epoch=49, lrate=0.100, error=119.296\n",
      ">epoch=50, lrate=0.100, error=119.033\n",
      ">epoch=51, lrate=0.100, error=118.775\n",
      ">epoch=52, lrate=0.100, error=118.521\n",
      ">epoch=53, lrate=0.100, error=118.273\n",
      ">epoch=54, lrate=0.100, error=118.028\n",
      ">epoch=55, lrate=0.100, error=117.789\n",
      ">epoch=56, lrate=0.100, error=117.553\n",
      ">epoch=57, lrate=0.100, error=117.322\n",
      ">epoch=58, lrate=0.100, error=117.095\n",
      ">epoch=59, lrate=0.100, error=116.871\n",
      ">epoch=60, lrate=0.100, error=116.652\n",
      ">epoch=61, lrate=0.100, error=116.436\n",
      ">epoch=62, lrate=0.100, error=116.224\n",
      ">epoch=63, lrate=0.100, error=116.016\n",
      ">epoch=64, lrate=0.100, error=115.811\n",
      ">epoch=65, lrate=0.100, error=115.610\n",
      ">epoch=66, lrate=0.100, error=115.411\n",
      ">epoch=67, lrate=0.100, error=115.217\n",
      ">epoch=68, lrate=0.100, error=115.025\n",
      ">epoch=69, lrate=0.100, error=114.836\n",
      ">epoch=70, lrate=0.100, error=114.651\n",
      ">epoch=71, lrate=0.100, error=114.468\n",
      ">epoch=72, lrate=0.100, error=114.288\n",
      ">epoch=73, lrate=0.100, error=114.111\n",
      ">epoch=74, lrate=0.100, error=113.937\n",
      ">epoch=75, lrate=0.100, error=113.766\n",
      ">epoch=76, lrate=0.100, error=113.597\n",
      ">epoch=77, lrate=0.100, error=113.431\n",
      ">epoch=78, lrate=0.100, error=113.267\n",
      ">epoch=79, lrate=0.100, error=113.106\n",
      ">epoch=80, lrate=0.100, error=112.947\n",
      ">epoch=81, lrate=0.100, error=112.790\n",
      ">epoch=82, lrate=0.100, error=112.636\n",
      ">epoch=83, lrate=0.100, error=112.484\n",
      ">epoch=84, lrate=0.100, error=112.334\n",
      ">epoch=85, lrate=0.100, error=112.186\n",
      ">epoch=86, lrate=0.100, error=112.041\n",
      ">epoch=87, lrate=0.100, error=111.897\n",
      ">epoch=88, lrate=0.100, error=111.756\n",
      ">epoch=89, lrate=0.100, error=111.616\n",
      ">epoch=90, lrate=0.100, error=111.479\n",
      ">epoch=91, lrate=0.100, error=111.343\n",
      ">epoch=92, lrate=0.100, error=111.209\n",
      ">epoch=93, lrate=0.100, error=111.077\n",
      ">epoch=94, lrate=0.100, error=110.947\n",
      ">epoch=95, lrate=0.100, error=110.818\n",
      ">epoch=96, lrate=0.100, error=110.691\n",
      ">epoch=97, lrate=0.100, error=110.566\n",
      ">epoch=98, lrate=0.100, error=110.442\n",
      ">epoch=99, lrate=0.100, error=110.321\n",
      ">epoch=100, lrate=0.100, error=110.200\n",
      ">epoch=1, lrate=0.100, error=147.543\n",
      ">epoch=2, lrate=0.100, error=142.472\n",
      ">epoch=3, lrate=0.100, error=140.998\n",
      ">epoch=4, lrate=0.100, error=140.189\n",
      ">epoch=5, lrate=0.100, error=139.514\n",
      ">epoch=6, lrate=0.100, error=138.869\n",
      ">epoch=7, lrate=0.100, error=138.236\n",
      ">epoch=8, lrate=0.100, error=137.614\n",
      ">epoch=9, lrate=0.100, error=137.003\n",
      ">epoch=10, lrate=0.100, error=136.404\n",
      ">epoch=11, lrate=0.100, error=135.818\n",
      ">epoch=12, lrate=0.100, error=135.245\n",
      ">epoch=13, lrate=0.100, error=134.683\n",
      ">epoch=14, lrate=0.100, error=134.134\n",
      ">epoch=15, lrate=0.100, error=133.598\n",
      ">epoch=16, lrate=0.100, error=133.072\n",
      ">epoch=17, lrate=0.100, error=132.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=18, lrate=0.100, error=132.056\n",
      ">epoch=19, lrate=0.100, error=131.565\n",
      ">epoch=20, lrate=0.100, error=131.084\n",
      ">epoch=21, lrate=0.100, error=130.614\n",
      ">epoch=22, lrate=0.100, error=130.153\n",
      ">epoch=23, lrate=0.100, error=129.703\n",
      ">epoch=24, lrate=0.100, error=129.262\n",
      ">epoch=25, lrate=0.100, error=128.831\n",
      ">epoch=26, lrate=0.100, error=128.409\n",
      ">epoch=27, lrate=0.100, error=127.995\n",
      ">epoch=28, lrate=0.100, error=127.590\n",
      ">epoch=29, lrate=0.100, error=127.194\n",
      ">epoch=30, lrate=0.100, error=126.806\n",
      ">epoch=31, lrate=0.100, error=126.426\n",
      ">epoch=32, lrate=0.100, error=126.053\n",
      ">epoch=33, lrate=0.100, error=125.689\n",
      ">epoch=34, lrate=0.100, error=125.331\n",
      ">epoch=35, lrate=0.100, error=124.981\n",
      ">epoch=36, lrate=0.100, error=124.637\n",
      ">epoch=37, lrate=0.100, error=124.301\n",
      ">epoch=38, lrate=0.100, error=123.971\n",
      ">epoch=39, lrate=0.100, error=123.648\n",
      ">epoch=40, lrate=0.100, error=123.330\n",
      ">epoch=41, lrate=0.100, error=123.019\n",
      ">epoch=42, lrate=0.100, error=122.714\n",
      ">epoch=43, lrate=0.100, error=122.415\n",
      ">epoch=44, lrate=0.100, error=122.121\n",
      ">epoch=45, lrate=0.100, error=121.833\n",
      ">epoch=46, lrate=0.100, error=121.550\n",
      ">epoch=47, lrate=0.100, error=121.272\n",
      ">epoch=48, lrate=0.100, error=121.000\n",
      ">epoch=49, lrate=0.100, error=120.732\n",
      ">epoch=50, lrate=0.100, error=120.469\n",
      ">epoch=51, lrate=0.100, error=120.211\n",
      ">epoch=52, lrate=0.100, error=119.958\n",
      ">epoch=53, lrate=0.100, error=119.709\n",
      ">epoch=54, lrate=0.100, error=119.464\n",
      ">epoch=55, lrate=0.100, error=119.224\n",
      ">epoch=56, lrate=0.100, error=118.987\n",
      ">epoch=57, lrate=0.100, error=118.755\n",
      ">epoch=58, lrate=0.100, error=118.527\n",
      ">epoch=59, lrate=0.100, error=118.302\n",
      ">epoch=60, lrate=0.100, error=118.081\n",
      ">epoch=61, lrate=0.100, error=117.864\n",
      ">epoch=62, lrate=0.100, error=117.651\n",
      ">epoch=63, lrate=0.100, error=117.441\n",
      ">epoch=64, lrate=0.100, error=117.234\n",
      ">epoch=65, lrate=0.100, error=117.031\n",
      ">epoch=66, lrate=0.100, error=116.831\n",
      ">epoch=67, lrate=0.100, error=116.634\n",
      ">epoch=68, lrate=0.100, error=116.440\n",
      ">epoch=69, lrate=0.100, error=116.249\n",
      ">epoch=70, lrate=0.100, error=116.061\n",
      ">epoch=71, lrate=0.100, error=115.876\n",
      ">epoch=72, lrate=0.100, error=115.694\n",
      ">epoch=73, lrate=0.100, error=115.515\n",
      ">epoch=74, lrate=0.100, error=115.338\n",
      ">epoch=75, lrate=0.100, error=115.164\n",
      ">epoch=76, lrate=0.100, error=114.992\n",
      ">epoch=77, lrate=0.100, error=114.823\n",
      ">epoch=78, lrate=0.100, error=114.657\n",
      ">epoch=79, lrate=0.100, error=114.493\n",
      ">epoch=80, lrate=0.100, error=114.331\n",
      ">epoch=81, lrate=0.100, error=114.171\n",
      ">epoch=82, lrate=0.100, error=114.014\n",
      ">epoch=83, lrate=0.100, error=113.859\n",
      ">epoch=84, lrate=0.100, error=113.706\n",
      ">epoch=85, lrate=0.100, error=113.555\n",
      ">epoch=86, lrate=0.100, error=113.407\n",
      ">epoch=87, lrate=0.100, error=113.260\n",
      ">epoch=88, lrate=0.100, error=113.115\n",
      ">epoch=89, lrate=0.100, error=112.973\n",
      ">epoch=90, lrate=0.100, error=112.832\n",
      ">epoch=91, lrate=0.100, error=112.693\n",
      ">epoch=92, lrate=0.100, error=112.556\n",
      ">epoch=93, lrate=0.100, error=112.421\n",
      ">epoch=94, lrate=0.100, error=112.287\n",
      ">epoch=95, lrate=0.100, error=112.155\n",
      ">epoch=96, lrate=0.100, error=112.025\n",
      ">epoch=97, lrate=0.100, error=111.896\n",
      ">epoch=98, lrate=0.100, error=111.770\n",
      ">epoch=99, lrate=0.100, error=111.644\n",
      ">epoch=100, lrate=0.100, error=111.521\n",
      ">epoch=1, lrate=0.100, error=147.398\n",
      ">epoch=2, lrate=0.100, error=142.254\n",
      ">epoch=3, lrate=0.100, error=140.783\n",
      ">epoch=4, lrate=0.100, error=139.986\n",
      ">epoch=5, lrate=0.100, error=139.323\n",
      ">epoch=6, lrate=0.100, error=138.688\n",
      ">epoch=7, lrate=0.100, error=138.065\n",
      ">epoch=8, lrate=0.100, error=137.450\n",
      ">epoch=9, lrate=0.100, error=136.847\n",
      ">epoch=10, lrate=0.100, error=136.254\n",
      ">epoch=11, lrate=0.100, error=135.673\n",
      ">epoch=12, lrate=0.100, error=135.104\n",
      ">epoch=13, lrate=0.100, error=134.547\n",
      ">epoch=14, lrate=0.100, error=134.002\n",
      ">epoch=15, lrate=0.100, error=133.468\n",
      ">epoch=16, lrate=0.100, error=132.945\n",
      ">epoch=17, lrate=0.100, error=132.433\n",
      ">epoch=18, lrate=0.100, error=131.933\n",
      ">epoch=19, lrate=0.100, error=131.442\n",
      ">epoch=20, lrate=0.100, error=130.962\n",
      ">epoch=21, lrate=0.100, error=130.492\n",
      ">epoch=22, lrate=0.100, error=130.032\n",
      ">epoch=23, lrate=0.100, error=129.582\n",
      ">epoch=24, lrate=0.100, error=129.140\n",
      ">epoch=25, lrate=0.100, error=128.708\n",
      ">epoch=26, lrate=0.100, error=128.285\n",
      ">epoch=27, lrate=0.100, error=127.870\n",
      ">epoch=28, lrate=0.100, error=127.464\n",
      ">epoch=29, lrate=0.100, error=127.067\n",
      ">epoch=30, lrate=0.100, error=126.677\n",
      ">epoch=31, lrate=0.100, error=126.295\n",
      ">epoch=32, lrate=0.100, error=125.921\n",
      ">epoch=33, lrate=0.100, error=125.554\n",
      ">epoch=34, lrate=0.100, error=125.194\n",
      ">epoch=35, lrate=0.100, error=124.842\n",
      ">epoch=36, lrate=0.100, error=124.496\n",
      ">epoch=37, lrate=0.100, error=124.157\n",
      ">epoch=38, lrate=0.100, error=123.825\n",
      ">epoch=39, lrate=0.100, error=123.499\n",
      ">epoch=40, lrate=0.100, error=123.180\n",
      ">epoch=41, lrate=0.100, error=122.866\n",
      ">epoch=42, lrate=0.100, error=122.559\n",
      ">epoch=43, lrate=0.100, error=122.257\n",
      ">epoch=44, lrate=0.100, error=121.961\n",
      ">epoch=45, lrate=0.100, error=121.670\n",
      ">epoch=46, lrate=0.100, error=121.385\n",
      ">epoch=47, lrate=0.100, error=121.105\n",
      ">epoch=48, lrate=0.100, error=120.830\n",
      ">epoch=49, lrate=0.100, error=120.560\n",
      ">epoch=50, lrate=0.100, error=120.295\n",
      ">epoch=51, lrate=0.100, error=120.035\n",
      ">epoch=52, lrate=0.100, error=119.779\n",
      ">epoch=53, lrate=0.100, error=119.528\n",
      ">epoch=54, lrate=0.100, error=119.281\n",
      ">epoch=55, lrate=0.100, error=119.039\n",
      ">epoch=56, lrate=0.100, error=118.800\n",
      ">epoch=57, lrate=0.100, error=118.566\n",
      ">epoch=58, lrate=0.100, error=118.336\n",
      ">epoch=59, lrate=0.100, error=118.109\n",
      ">epoch=60, lrate=0.100, error=117.887\n",
      ">epoch=61, lrate=0.100, error=117.668\n",
      ">epoch=62, lrate=0.100, error=117.453\n",
      ">epoch=63, lrate=0.100, error=117.241\n",
      ">epoch=64, lrate=0.100, error=117.033\n",
      ">epoch=65, lrate=0.100, error=116.828\n",
      ">epoch=66, lrate=0.100, error=116.627\n",
      ">epoch=67, lrate=0.100, error=116.429\n",
      ">epoch=68, lrate=0.100, error=116.234\n",
      ">epoch=69, lrate=0.100, error=116.042\n",
      ">epoch=70, lrate=0.100, error=115.853\n",
      ">epoch=71, lrate=0.100, error=115.667\n",
      ">epoch=72, lrate=0.100, error=115.484\n",
      ">epoch=73, lrate=0.100, error=115.303\n",
      ">epoch=74, lrate=0.100, error=115.126\n",
      ">epoch=75, lrate=0.100, error=114.951\n",
      ">epoch=76, lrate=0.100, error=114.779\n",
      ">epoch=77, lrate=0.100, error=114.609\n",
      ">epoch=78, lrate=0.100, error=114.442\n",
      ">epoch=79, lrate=0.100, error=114.278\n",
      ">epoch=80, lrate=0.100, error=114.115\n",
      ">epoch=81, lrate=0.100, error=113.956\n",
      ">epoch=82, lrate=0.100, error=113.798\n",
      ">epoch=83, lrate=0.100, error=113.643\n",
      ">epoch=84, lrate=0.100, error=113.490\n",
      ">epoch=85, lrate=0.100, error=113.339\n",
      ">epoch=86, lrate=0.100, error=113.190\n",
      ">epoch=87, lrate=0.100, error=113.044\n",
      ">epoch=88, lrate=0.100, error=112.899\n",
      ">epoch=89, lrate=0.100, error=112.757\n",
      ">epoch=90, lrate=0.100, error=112.616\n",
      ">epoch=91, lrate=0.100, error=112.477\n",
      ">epoch=92, lrate=0.100, error=112.341\n",
      ">epoch=93, lrate=0.100, error=112.206\n",
      ">epoch=94, lrate=0.100, error=112.072\n",
      ">epoch=95, lrate=0.100, error=111.941\n",
      ">epoch=96, lrate=0.100, error=111.812\n",
      ">epoch=97, lrate=0.100, error=111.684\n",
      ">epoch=98, lrate=0.100, error=111.557\n",
      ">epoch=99, lrate=0.100, error=111.433\n",
      ">epoch=100, lrate=0.100, error=111.310\n",
      ">epoch=1, lrate=0.100, error=147.420\n",
      ">epoch=2, lrate=0.100, error=142.270\n",
      ">epoch=3, lrate=0.100, error=140.776\n",
      ">epoch=4, lrate=0.100, error=139.953\n",
      ">epoch=5, lrate=0.100, error=139.264\n",
      ">epoch=6, lrate=0.100, error=138.605\n",
      ">epoch=7, lrate=0.100, error=137.958\n",
      ">epoch=8, lrate=0.100, error=137.322\n",
      ">epoch=9, lrate=0.100, error=136.697\n",
      ">epoch=10, lrate=0.100, error=136.084\n",
      ">epoch=11, lrate=0.100, error=135.484\n",
      ">epoch=12, lrate=0.100, error=134.897\n",
      ">epoch=13, lrate=0.100, error=134.322\n",
      ">epoch=14, lrate=0.100, error=133.761\n",
      ">epoch=15, lrate=0.100, error=133.211\n",
      ">epoch=16, lrate=0.100, error=132.674\n",
      ">epoch=17, lrate=0.100, error=132.148\n",
      ">epoch=18, lrate=0.100, error=131.634\n",
      ">epoch=19, lrate=0.100, error=131.131\n",
      ">epoch=20, lrate=0.100, error=130.639\n",
      ">epoch=21, lrate=0.100, error=130.157\n",
      ">epoch=22, lrate=0.100, error=129.686\n",
      ">epoch=23, lrate=0.100, error=129.226\n",
      ">epoch=24, lrate=0.100, error=128.775\n",
      ">epoch=25, lrate=0.100, error=128.333\n",
      ">epoch=26, lrate=0.100, error=127.901\n",
      ">epoch=27, lrate=0.100, error=127.479\n",
      ">epoch=28, lrate=0.100, error=127.065\n",
      ">epoch=29, lrate=0.100, error=126.659\n",
      ">epoch=30, lrate=0.100, error=126.262\n",
      ">epoch=31, lrate=0.100, error=125.874\n",
      ">epoch=32, lrate=0.100, error=125.493\n",
      ">epoch=33, lrate=0.100, error=125.120\n",
      ">epoch=34, lrate=0.100, error=124.755\n",
      ">epoch=35, lrate=0.100, error=124.397\n",
      ">epoch=36, lrate=0.100, error=124.046\n",
      ">epoch=37, lrate=0.100, error=123.702\n",
      ">epoch=38, lrate=0.100, error=123.365\n",
      ">epoch=39, lrate=0.100, error=123.034\n",
      ">epoch=40, lrate=0.100, error=122.710\n",
      ">epoch=41, lrate=0.100, error=122.392\n",
      ">epoch=42, lrate=0.100, error=122.081\n",
      ">epoch=43, lrate=0.100, error=121.775\n",
      ">epoch=44, lrate=0.100, error=121.475\n",
      ">epoch=45, lrate=0.100, error=121.181\n",
      ">epoch=46, lrate=0.100, error=120.892\n",
      ">epoch=47, lrate=0.100, error=120.608\n",
      ">epoch=48, lrate=0.100, error=120.330\n",
      ">epoch=49, lrate=0.100, error=120.056\n",
      ">epoch=50, lrate=0.100, error=119.788\n",
      ">epoch=51, lrate=0.100, error=119.525\n",
      ">epoch=52, lrate=0.100, error=119.266\n",
      ">epoch=53, lrate=0.100, error=119.011\n",
      ">epoch=54, lrate=0.100, error=118.762\n",
      ">epoch=55, lrate=0.100, error=118.516\n",
      ">epoch=56, lrate=0.100, error=118.275\n",
      ">epoch=57, lrate=0.100, error=118.038\n",
      ">epoch=58, lrate=0.100, error=117.805\n",
      ">epoch=59, lrate=0.100, error=117.575\n",
      ">epoch=60, lrate=0.100, error=117.350\n",
      ">epoch=61, lrate=0.100, error=117.128\n",
      ">epoch=62, lrate=0.100, error=116.910\n",
      ">epoch=63, lrate=0.100, error=116.696\n",
      ">epoch=64, lrate=0.100, error=116.485\n",
      ">epoch=65, lrate=0.100, error=116.278\n",
      ">epoch=66, lrate=0.100, error=116.073\n",
      ">epoch=67, lrate=0.100, error=115.872\n",
      ">epoch=68, lrate=0.100, error=115.674\n",
      ">epoch=69, lrate=0.100, error=115.480\n",
      ">epoch=70, lrate=0.100, error=115.288\n",
      ">epoch=71, lrate=0.100, error=115.099\n",
      ">epoch=72, lrate=0.100, error=114.913\n",
      ">epoch=73, lrate=0.100, error=114.730\n",
      ">epoch=74, lrate=0.100, error=114.550\n",
      ">epoch=75, lrate=0.100, error=114.372\n",
      ">epoch=76, lrate=0.100, error=114.197\n",
      ">epoch=77, lrate=0.100, error=114.025\n",
      ">epoch=78, lrate=0.100, error=113.855\n",
      ">epoch=79, lrate=0.100, error=113.687\n",
      ">epoch=80, lrate=0.100, error=113.522\n",
      ">epoch=81, lrate=0.100, error=113.359\n",
      ">epoch=82, lrate=0.100, error=113.199\n",
      ">epoch=83, lrate=0.100, error=113.041\n",
      ">epoch=84, lrate=0.100, error=112.885\n",
      ">epoch=85, lrate=0.100, error=112.731\n",
      ">epoch=86, lrate=0.100, error=112.579\n",
      ">epoch=87, lrate=0.100, error=112.429\n",
      ">epoch=88, lrate=0.100, error=112.282\n",
      ">epoch=89, lrate=0.100, error=112.136\n",
      ">epoch=90, lrate=0.100, error=111.993\n",
      ">epoch=91, lrate=0.100, error=111.851\n",
      ">epoch=92, lrate=0.100, error=111.711\n",
      ">epoch=93, lrate=0.100, error=111.573\n",
      ">epoch=94, lrate=0.100, error=111.437\n",
      ">epoch=95, lrate=0.100, error=111.302\n",
      ">epoch=96, lrate=0.100, error=111.169\n",
      ">epoch=97, lrate=0.100, error=111.038\n",
      ">epoch=98, lrate=0.100, error=110.909\n",
      ">epoch=99, lrate=0.100, error=110.781\n",
      ">epoch=100, lrate=0.100, error=110.655\n",
      ">epoch=1, lrate=0.100, error=148.501\n",
      ">epoch=2, lrate=0.100, error=144.054\n",
      ">epoch=3, lrate=0.100, error=142.545\n",
      ">epoch=4, lrate=0.100, error=141.600\n",
      ">epoch=5, lrate=0.100, error=140.778\n",
      ">epoch=6, lrate=0.100, error=139.989\n",
      ">epoch=7, lrate=0.100, error=139.218\n",
      ">epoch=8, lrate=0.100, error=138.463\n",
      ">epoch=9, lrate=0.100, error=137.724\n",
      ">epoch=10, lrate=0.100, error=137.000\n",
      ">epoch=11, lrate=0.100, error=136.293\n",
      ">epoch=12, lrate=0.100, error=135.602\n",
      ">epoch=13, lrate=0.100, error=134.927\n",
      ">epoch=14, lrate=0.100, error=134.267\n",
      ">epoch=15, lrate=0.100, error=133.623\n",
      ">epoch=16, lrate=0.100, error=132.993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=17, lrate=0.100, error=132.378\n",
      ">epoch=18, lrate=0.100, error=131.777\n",
      ">epoch=19, lrate=0.100, error=131.189\n",
      ">epoch=20, lrate=0.100, error=130.616\n",
      ">epoch=21, lrate=0.100, error=130.055\n",
      ">epoch=22, lrate=0.100, error=129.507\n",
      ">epoch=23, lrate=0.100, error=128.971\n",
      ">epoch=24, lrate=0.100, error=128.448\n",
      ">epoch=25, lrate=0.100, error=127.936\n",
      ">epoch=26, lrate=0.100, error=127.436\n",
      ">epoch=27, lrate=0.100, error=126.946\n",
      ">epoch=28, lrate=0.100, error=126.468\n",
      ">epoch=29, lrate=0.100, error=126.000\n",
      ">epoch=30, lrate=0.100, error=125.543\n",
      ">epoch=31, lrate=0.100, error=125.095\n",
      ">epoch=32, lrate=0.100, error=124.657\n",
      ">epoch=33, lrate=0.100, error=124.229\n",
      ">epoch=34, lrate=0.100, error=123.809\n",
      ">epoch=35, lrate=0.100, error=123.399\n",
      ">epoch=36, lrate=0.100, error=122.997\n",
      ">epoch=37, lrate=0.100, error=122.604\n",
      ">epoch=38, lrate=0.100, error=122.219\n",
      ">epoch=39, lrate=0.100, error=121.842\n",
      ">epoch=40, lrate=0.100, error=121.473\n",
      ">epoch=41, lrate=0.100, error=121.111\n",
      ">epoch=42, lrate=0.100, error=120.757\n",
      ">epoch=43, lrate=0.100, error=120.409\n",
      ">epoch=44, lrate=0.100, error=120.069\n",
      ">epoch=45, lrate=0.100, error=119.736\n",
      ">epoch=46, lrate=0.100, error=119.409\n",
      ">epoch=47, lrate=0.100, error=119.088\n",
      ">epoch=48, lrate=0.100, error=118.774\n",
      ">epoch=49, lrate=0.100, error=118.466\n",
      ">epoch=50, lrate=0.100, error=118.164\n",
      ">epoch=51, lrate=0.100, error=117.868\n",
      ">epoch=52, lrate=0.100, error=117.577\n",
      ">epoch=53, lrate=0.100, error=117.291\n",
      ">epoch=54, lrate=0.100, error=117.011\n",
      ">epoch=55, lrate=0.100, error=116.737\n",
      ">epoch=56, lrate=0.100, error=116.467\n",
      ">epoch=57, lrate=0.100, error=116.202\n",
      ">epoch=58, lrate=0.100, error=115.942\n",
      ">epoch=59, lrate=0.100, error=115.687\n",
      ">epoch=60, lrate=0.100, error=115.436\n",
      ">epoch=61, lrate=0.100, error=115.190\n",
      ">epoch=62, lrate=0.100, error=114.948\n",
      ">epoch=63, lrate=0.100, error=114.710\n",
      ">epoch=64, lrate=0.100, error=114.476\n",
      ">epoch=65, lrate=0.100, error=114.247\n",
      ">epoch=66, lrate=0.100, error=114.021\n",
      ">epoch=67, lrate=0.100, error=113.800\n",
      ">epoch=68, lrate=0.100, error=113.582\n",
      ">epoch=69, lrate=0.100, error=113.367\n",
      ">epoch=70, lrate=0.100, error=113.156\n",
      ">epoch=71, lrate=0.100, error=112.949\n",
      ">epoch=72, lrate=0.100, error=112.745\n",
      ">epoch=73, lrate=0.100, error=112.545\n",
      ">epoch=74, lrate=0.100, error=112.347\n",
      ">epoch=75, lrate=0.100, error=112.153\n",
      ">epoch=76, lrate=0.100, error=111.962\n",
      ">epoch=77, lrate=0.100, error=111.774\n",
      ">epoch=78, lrate=0.100, error=111.589\n",
      ">epoch=79, lrate=0.100, error=111.407\n",
      ">epoch=80, lrate=0.100, error=111.227\n",
      ">epoch=81, lrate=0.100, error=111.051\n",
      ">epoch=82, lrate=0.100, error=110.877\n",
      ">epoch=83, lrate=0.100, error=110.706\n",
      ">epoch=84, lrate=0.100, error=110.537\n",
      ">epoch=85, lrate=0.100, error=110.371\n",
      ">epoch=86, lrate=0.100, error=110.207\n",
      ">epoch=87, lrate=0.100, error=110.046\n",
      ">epoch=88, lrate=0.100, error=109.887\n",
      ">epoch=89, lrate=0.100, error=109.731\n",
      ">epoch=90, lrate=0.100, error=109.576\n",
      ">epoch=91, lrate=0.100, error=109.424\n",
      ">epoch=92, lrate=0.100, error=109.275\n",
      ">epoch=93, lrate=0.100, error=109.127\n",
      ">epoch=94, lrate=0.100, error=108.981\n",
      ">epoch=95, lrate=0.100, error=108.838\n",
      ">epoch=96, lrate=0.100, error=108.696\n",
      ">epoch=97, lrate=0.100, error=108.557\n",
      ">epoch=98, lrate=0.100, error=108.419\n",
      ">epoch=99, lrate=0.100, error=108.283\n",
      ">epoch=100, lrate=0.100, error=108.149\n",
      "Scores: [69.93464052287581, 73.20261437908496, 71.24183006535948, 71.24183006535948, 75.81699346405229]\n",
      "Mean Accuracy: 72.288%\n"
     ]
    }
   ],
   "source": [
    "# Contrived dataset for prediction testing\n",
    "dataset =   [[2.7810836,2.550537003,0],\n",
    "            [1.465489372,2.362125076,0],\n",
    "            [3.396561688,4.400293529,0],\n",
    "            [1.38807019,1.850220317,0],\n",
    "            [3.06407232,3.005305973,0],\n",
    "            [7.627531214,2.759262235,1],\n",
    "            [5.332441248,2.088626775,1],\n",
    "            [6.922596716,1.77106367,1],\n",
    "            [8.675418651,-0.242068655,1],\n",
    "            [7.673756466,3.508563011,1]]\n",
    "# Hardcoded coefficients for testing\n",
    "coef = [-0.406605464, 0.852573316, -1.104746259]\n",
    "# Iterating over rows and predicting using \"provided\" coefficients\n",
    "for row in dataset:\n",
    "    yhat = predict_logistic(row, coef)\n",
    "    print(\"Expected=%.3f, Predicted=%.3f [%d]\" % (round(row[-1]), yhat, round(yhat)))\n",
    "\n",
    "# Testing estimating coefficients using SGD on contrived dataset\n",
    "print()\n",
    "l_rate = 0.3\n",
    "n_epoch = 100\n",
    "coef = coefficients_logistic_sgd(dataset, l_rate, n_epoch)\n",
    "print(coef)\n",
    "\n",
    "# Logistic Regression using Stochastic Gradient Descent for Pima Indians\n",
    "seed(1)\n",
    "print(\"\\nLinear Regression With Stochastic Gradient Descent for Wine Quality:\")\n",
    "\n",
    "# Load data and convert all columns to float\n",
    "dataset = load_csv('data/pima-indians-diabetes.csv')\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "# Normalize data (to between 0 and 1)\n",
    "minmax = dataset_minmax(dataset)\n",
    "normalize_dataset(dataset, minmax)\n",
    "\n",
    "# Evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = 0.1\n",
    "n_epoch = 100\n",
    "batch_size = 10\n",
    "scores = evaluate_algorithm(dataset, logistic_regression_sgd, n_folds, accuracy_metric, l_rate, n_epoch, batch_size)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Error continues to drop, so could train for a lot more epochs or increase learning rate (perhaps with some decay scheme), but it gets the point across...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
